{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:"
      ],
      "metadata": {
        "id": "fPF_GAmB62ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "btSUUw4e0Ycj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('grammar_correction_pairs.csv')\n",
        "\n",
        "# Prepare training data\n",
        "incorrect_sentences = df['incorrect_sentence'].values\n",
        "correct_sentences = df['correct_sentence'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization:"
      ],
      "metadata": {
        "id": "ZPV3n3k763eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(incorrect_sentences) + list(correct_sentences))\n",
        "\n",
        "# Convert text to sequences\n",
        "X = tokenizer.texts_to_sequences(incorrect_sentences)\n",
        "y = tokenizer.texts_to_sequences(correct_sentences)\n",
        "\n",
        "# Pad sequences to make them the same length\n",
        "X = pad_sequences(X, padding='post')\n",
        "y = pad_sequences(y, padding='post')"
      ],
      "metadata": {
        "id": "iROm87480t-4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model:\n"
      ],
      "metadata": {
        "id": "pPQDiSRr7MwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Define embedding layer\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=256, input_length=X.shape[1]))\n",
        "\n",
        "# Encoder\n",
        "model.add(LSTM(256))\n",
        "\n",
        "# Decoder\n",
        "model.add(RepeatVector(X.shape[1]))  # Repeat the context vector\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV2s2nW667Ro",
        "outputId": "4e5904a4-fd77-4c1c-a44a-23c8de9d75f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model:"
      ],
      "metadata": {
        "id": "IH2K4EwN7PTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, batch_size=64, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAG4NPQL7OJt",
        "outputId": "d9414da5-f262-4a94-c69a-3b2e03689a32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 147ms/step - accuracy: 0.8389 - loss: 0.6173 - val_accuracy: 0.4943 - val_loss: 4.3105\n",
            "Epoch 2/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 140ms/step - accuracy: 0.9022 - loss: 0.4108 - val_accuracy: 0.5163 - val_loss: 4.2136\n",
            "Epoch 3/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 133ms/step - accuracy: 0.9186 - loss: 0.2952 - val_accuracy: 0.5391 - val_loss: 4.2598\n",
            "Epoch 4/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 146ms/step - accuracy: 0.9317 - loss: 0.2260 - val_accuracy: 0.5631 - val_loss: 4.0822\n",
            "Epoch 5/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 127ms/step - accuracy: 0.9468 - loss: 0.1801 - val_accuracy: 0.5682 - val_loss: 4.2124\n",
            "Epoch 6/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 152ms/step - accuracy: 0.9655 - loss: 0.1304 - val_accuracy: 0.5901 - val_loss: 4.1724\n",
            "Epoch 7/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 150ms/step - accuracy: 0.9780 - loss: 0.0919 - val_accuracy: 0.5919 - val_loss: 4.2377\n",
            "Epoch 8/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 135ms/step - accuracy: 0.9860 - loss: 0.0653 - val_accuracy: 0.5999 - val_loss: 4.3347\n",
            "Epoch 9/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 133ms/step - accuracy: 0.9902 - loss: 0.0462 - val_accuracy: 0.5931 - val_loss: 4.4222\n",
            "Epoch 10/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 134ms/step - accuracy: 0.9940 - loss: 0.0317 - val_accuracy: 0.5904 - val_loss: 4.5228\n",
            "Epoch 11/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 135ms/step - accuracy: 0.9971 - loss: 0.0207 - val_accuracy: 0.5966 - val_loss: 4.4551\n",
            "Epoch 12/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 132ms/step - accuracy: 0.9984 - loss: 0.0150 - val_accuracy: 0.5903 - val_loss: 4.6066\n",
            "Epoch 13/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 134ms/step - accuracy: 0.9946 - loss: 0.0280 - val_accuracy: 0.5732 - val_loss: 4.5884\n",
            "Epoch 14/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 134ms/step - accuracy: 0.9959 - loss: 0.0214 - val_accuracy: 0.5925 - val_loss: 4.4852\n",
            "Epoch 15/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 135ms/step - accuracy: 0.9990 - loss: 0.0095 - val_accuracy: 0.5893 - val_loss: 4.6072\n",
            "Epoch 16/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 127ms/step - accuracy: 0.9995 - loss: 0.0058 - val_accuracy: 0.5902 - val_loss: 4.6396\n",
            "Epoch 17/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 134ms/step - accuracy: 0.9998 - loss: 0.0043 - val_accuracy: 0.5879 - val_loss: 4.7048\n",
            "Epoch 18/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 133ms/step - accuracy: 0.9999 - loss: 0.0032 - val_accuracy: 0.5900 - val_loss: 4.6887\n",
            "Epoch 19/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.5926 - val_loss: 4.7021\n",
            "Epoch 20/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.5895 - val_loss: 4.7531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d24ac218e50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference:\n"
      ],
      "metadata": {
        "id": "8q87cmWh-OVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the corrected sentence\n",
        "def correct_grammar(input_sentence):\n",
        "    seq_input = tokenizer.texts_to_sequences([input_sentence])\n",
        "    padded_input = pad_sequences(seq_input, padding='post', maxlen=X.shape[1])\n",
        "\n",
        "    pred = model.predict(padded_input)\n",
        "\n",
        "    # Convert prediction to words\n",
        "    pred_sentence = ' '.join([tokenizer.index_word.get(idx, '') for idx in pred[0].argmax(axis=-1)])\n",
        "    return pred_sentence"
      ],
      "metadata": {
        "id": "wrOhGAcT7Sib"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Input:"
      ],
      "metadata": {
        "id": "ot4EmWiS-SNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input and correct grammar\n",
        "user_input = input(\"Enter a sentence with possible grammar errors: \")\n",
        "corrected_sentence = correct_grammar(user_input)\n",
        "print(\"Corrected sentence:\", corrected_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxwz7ftc-P0i",
        "outputId": "65835624-5fba-4e8d-880f-95e67783c62e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence with possible grammar errors: මම යන්නෙමු\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
            "Corrected sentence: මම යන්නෙමි     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grammar Correction Function for Paragraphs:"
      ],
      "metadata": {
        "id": "iV5ikD63_OgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Function to split paragraph into sentences by period (.)\n",
        "def split_paragraph_into_sentences(paragraph):\n",
        "    # Split the paragraph by punctuation mark (.)\n",
        "    sentences = paragraph.split(\".\")\n",
        "\n",
        "    # Clean up sentences (remove empty sentences after split)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "# Function to correct a single sentence (using the trained model)\n",
        "def correct_grammar_for_sentence(input_sentence, tokenizer, model, max_input_length):\n",
        "    # Tokenize and pad the input sentence\n",
        "    seq_input = tokenizer.texts_to_sequences([input_sentence])\n",
        "    padded_input = pad_sequences(seq_input, padding='post', maxlen=max_input_length)\n",
        "\n",
        "    # Predict the corrected sentence\n",
        "    pred = model.predict(padded_input)\n",
        "\n",
        "    # Convert prediction to words\n",
        "    pred_sentence = ' '.join([tokenizer.index_word.get(idx, '') for idx in pred[0].argmax(axis=-1)])\n",
        "    return pred_sentence\n",
        "\n",
        "# Function to correct grammar in an entire paragraph\n",
        "def correct_grammar_in_paragraph(paragraph, tokenizer, model, max_input_length):\n",
        "    # Step 1: Split the paragraph into sentences\n",
        "    sentences = split_paragraph_into_sentences(paragraph)\n",
        "\n",
        "    # Step 2: Correct each sentence\n",
        "    corrected_sentences = [correct_grammar_for_sentence(sentence, tokenizer, model, max_input_length) for sentence in sentences]\n",
        "\n",
        "    # Step 3: Join the corrected sentences back into a paragraph\n",
        "    corrected_paragraph = '. '.join(corrected_sentences) + '.' if corrected_sentences else ''\n",
        "\n",
        "    return corrected_paragraph"
      ],
      "metadata": {
        "id": "b6Tky1ro-Wq5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paragraph 01:"
      ],
      "metadata": {
        "id": "gGAlEUXy5YKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_paragraph = \"මම යන්නෙමු. අපි යනවා. මම යවන්නෙමි. මම යවන්නෙහි. මම ගියාය. අපි යනවාලා.\"\n",
        "corrected_paragraph = correct_grammar_in_paragraph(user_paragraph, tokenizer, model, X.shape[1])\n",
        "\n",
        "print(\"Original Paragraph: \", user_paragraph)\n",
        "print(\"Corrected Paragraph: \", corrected_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQFP0Zxw_wOl",
        "outputId": "3baa3a9a-dbfc-49b6-d29f-be1ecbb48b29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Original Paragraph:  මම යන්නෙමු. අපි යනවා. මම යවන්නෙමි. මම යවන්නෙහි. මම ගියාය. අපි යනවාලා.\n",
            "Corrected Paragraph:  මම යන්නෙමි     . මම යැවෙමි     . මම යවන්නෙමි     . මම යවන්නෙමි     . මම ගියෙමි     . මම යැවෙමි     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paragraph 02:"
      ],
      "metadata": {
        "id": "wHhLjkmA5aye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_paragraph = \"මම යන්නෙමුවා. මම යන්නෙමි. මම යන්නෙහි. මම යන්නෙමි. මම යන්නෝය. මම යන්නෙමි. මම යමු. මම යමි. මම යවති මම යවමි. \\\n",
        "                  මම යවන්නෙහි. මම යවන්නෙමි. මම යවන්නෙමු. මම යවන්නෙමි. මම යව් මම යවමි.\"\n",
        "corrected_paragraph = correct_grammar_in_paragraph(user_paragraph, tokenizer, model, X.shape[1])\n",
        "\n",
        "print(\"Original Paragraph: \", user_paragraph)\n",
        "print(\"Corrected Paragraph: \", corrected_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjOgifxF68lr",
        "outputId": "9ef7d5e1-2c8b-4370-c838-4e6bdadfea29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Original Paragraph:  මම යන්නෙමුවා. මම යන්නෙමි. මම යන්නෙහි. මම යන්නෙමි. මම යන්නෝය. මම යන්නෙමි. මම යමු. මම යමි. මම යවති මම යවමි.                   මම යවන්නෙහි. මම යවන්නෙමි. මම යවන්නෙමු. මම යවන්නෙමි. මම යව් මම යවමි.\n",
            "Corrected Paragraph:  මම යන්නෙමි     . වාහන යන්නෙමි     . මම යන්නෙමි     . වාහන යන්නෙමි     . මම යන්නෙමි     . වාහන යන්නෙමි     . මම යමි     . මම යන්නෙමි     . මම ගෙදර යවමි    . මම යවන්නෙමි     . මම යවන්නෙමි     . මම යවන්නෙමි     . මම යවන්නෙමි     . මම යවන්නෙමි     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paragraph 03:"
      ],
      "metadata": {
        "id": "0OQSdt395bM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_paragraph = \"මම යනවා. මම ගියෙහි මම ගියෙමි. මම යැවෙති මම යැවෙමි. මම යැවවෙයි. මම යැවෙමු. මම යන්නෙමුවා. මම යන්නෙහි.\"\n",
        "corrected_paragraph = correct_grammar_in_paragraph(user_paragraph, tokenizer, model, X.shape[1])\n",
        "\n",
        "print(\"Original Paragraph: \", user_paragraph)\n",
        "print(\"Corrected Paragraph: \", corrected_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBaiN0YT7nZz",
        "outputId": "ce4b6418-d620-4ca7-f44d-1969f4fc8149"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Original Paragraph:  මම යනවා. මම ගියෙහි මම ගියෙමි. මම යැවෙති මම යැවෙමි. මම යැවවෙයි. මම යැවෙමු. මම යන්නෙමුවා. මම යන්නෙහි.\n",
            "Corrected Paragraph:  වාහන      . මම ගෙදර ගියෙමි    . මම මම යැවෙමි    . මම යැවෙමි     . මම යැවෙමි     . මම යන්නෙමි     . මම යන්නෙමි     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paragraph 04:"
      ],
      "metadata": {
        "id": "gnEMzPBP5bpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_paragraph = \"අපි යන්නෝය. අපි යමු. අපි යන්න. අපි යවමු. අපි ගියෙහු. අපි ගියෙමු. අපි යැවවෙති. අපි යැවෙමු. අපි යනවාලා. අපි යවන්නෙමු.\"\n",
        "corrected_paragraph = correct_grammar_in_paragraph(user_paragraph, tokenizer, model, X.shape[1])\n",
        "\n",
        "print(\"Original Paragraph: \", user_paragraph)\n",
        "print(\"Corrected Paragraph: \", corrected_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pVMpZ5d7t61",
        "outputId": "bd496bf3-e593-484b-98af-3b7f64522e2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Original Paragraph:  අපි යන්නෝය. අපි යමු. අපි යන්න. අපි යවමු. අපි ගියෙහු. අපි ගියෙමු. අපි යැවවෙති. අපි යැවෙමු. අපි යනවාලා. අපි යවන්නෙමු.\n",
            "Corrected Paragraph:  අපි යන්නෙමු     . අපි යන්නෙමු     . මම යැවෙමි     . අපි යවන්නෙමු     . අපි ගියෙමු     . අපි යවමු     . අපි යැවෙමු     . අපි යැවෙමු     . මම යැවෙමි     . අපි යවන්නෙමු     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paragraph 05:"
      ],
      "metadata": {
        "id": "4cBhpLAE6tRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_paragraph = \"මම යවන්නීය. මම යවන්නෙමි. මම යවන්නෙහු මම යවන්නෙමි. මම යමු. මම යවමි. මම ගියෙය. මම ගියෙමු. මම යතී මම යවති.\"\n",
        "corrected_paragraph = correct_grammar_in_paragraph(user_paragraph, tokenizer, model, X.shape[1])\n",
        "\n",
        "print(\"Original Paragraph: \", user_paragraph)\n",
        "print(\"Corrected Paragraph: \", corrected_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNiC-hpT8FYj",
        "outputId": "efd6c00f-7410-49ef-9268-0af2436198f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Original Paragraph:  මම යවන්නීය. මම යවන්නෙමි. මම යවන්නෙහු මම යවන්නෙමි. මම යමු. මම යවමි. මම ගියෙය. මම ගියෙමු. මම යතී මම යවති.\n",
            "Corrected Paragraph:  මම යමි     . මම යවන්නෙමි     . මම ඔහුට පොතක්    . මම යමි     . මම යවන්නෙමි     . වාහන      . මම ගියෙමි     . මම යමි     .\n"
          ]
        }
      ]
    }
  ]
}